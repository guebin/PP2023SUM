{
 "cells": [
  {
   "cell_type": "raw",
   "id": "38df310a-ab39-4d41-9d85-b2d2f2f089aa",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Lesson 11: groupby\"\n",
    "author: \"최규빈\"\n",
    "date: \"07/25/2023\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4123623b-c04e-4325-b690-c0c9d3dad8f4",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/guebin/PP2023SUM/blob/main/posts/Day2/04_Function, Iteration/ls11.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38fb6f53-1e47-444b-8d0c-22e4e91e8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a231ee7-4c9f-4004-96cd-310e956da214",
   "metadata": {},
   "source": [
    "# df.groupby "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2720db6-05fc-415c-baf7-73db0e1f204e",
   "metadata": {},
   "source": [
    "`-` 예제1: 아래의 예제에서 그룹별 평균을 구하여라. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "24d9842d-daf0-41db-a660-012f12276e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.255897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>1.633728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>-0.362963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>-1.216216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>-0.747245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B</td>\n",
       "      <td>9.460467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B</td>\n",
       "      <td>10.320092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B</td>\n",
       "      <td>10.051525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B</td>\n",
       "      <td>12.402084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B</td>\n",
       "      <td>10.005007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category      value\n",
       "0        A   0.255897\n",
       "1        A   1.633728\n",
       "2        A  -0.362963\n",
       "3        A  -1.216216\n",
       "4        A  -0.747245\n",
       "5        B   9.460467\n",
       "6        B  10.320092\n",
       "7        B  10.051525\n",
       "8        B  12.402084\n",
       "9        B  10.005007"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_category = ['A']*5+['B']*5\n",
    "_value = np.concatenate([np.random.randn(5), np.random.randn(5)+10])\n",
    "df = pd.DataFrame({'category':_category, 'value':_value})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4873f1e-9b30-4ed9-b671-e0d2f044156e",
   "metadata": {},
   "source": [
    "`-` 방법1: groupby를 이용하지 않는 방법들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3de79e8-6b17-4e4a-90ab-ce8e9f649000",
   "metadata": {},
   "source": [
    "`-` 방법2: groupby만 사용 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dc5f6b-16ea-4707-ba90-c9d354443b81",
   "metadata": {},
   "source": [
    "`-` 방법3: groupby().aggregate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d443f521-2d69-4d0f-a4aa-cb35600d270b",
   "metadata": {},
   "source": [
    "***groupby(?)에서 올 수 있는 구조***\n",
    "\n",
    "- 열의이름\n",
    "- [열의이름,열의이름]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c485afa4-546c-4eac-8eca-8d8c7f5e153f",
   "metadata": {},
   "source": [
    "***aggregate(?)에서 올 수 있는 구조***\n",
    "\n",
    "- 함수: 함수자체^[np.mean,sum]가 오거나, 함수를 의미하는 문자열^['size', 'count', 'sum', 'mean', 'median', 'min', 'max', 'std', 'var'] 이 올 수 있음. \n",
    "- 리스트: [함수, 함수] # 여기에서 함수자리에는 함수자체, 혹은 함수문자열 아무것이나 올 수 있음. \n",
    "- 딕셔너리1: {열의이름:함수} \n",
    "- 딕셔너리2: {열의이름:[함수,함수]} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9594d0-76f8-4f65-8c7c-2081fd5cb605",
   "metadata": {},
   "source": [
    "# pd.cut + df.groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cdf480-1f5c-4199-a049-60a4241a0667",
   "metadata": {},
   "source": [
    "`-` 구간별 count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e8dc8d6a-ea82-4fe8-8405-10b492002148",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.rand(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a2305c-b0f1-42a9-889b-6e2722de7727",
   "metadata": {},
   "source": [
    "`-` [0,0.2,0.5,0.9,1] 구간에 몇개의 숫자들이 있는지 알고 싶다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0c2099f5-40df-40c8-96fe-732fea512b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_cutted = pd.cut(arr,bins=[0,0.2,0.5,0.9,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "387c8983-01d9-4ed1-9336-ebad7972cae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bin\n",
       "(0.0, 0.2]    189\n",
       "(0.2, 0.5]    307\n",
       "(0.5, 0.9]    406\n",
       "(0.9, 1.0]     98\n",
       "dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'bin':pd_cutted}).groupby('bin').agg('size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04f9a26-82ff-4c5c-b270-ab776f011139",
   "metadata": {},
   "source": [
    "# flights data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c7c1864a-b6ee-4256-9c7c-876e43334c9c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58492 entries, 0 to 58491\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   MONTH      58492 non-null  int64  \n",
      " 1   DAY        58492 non-null  int64  \n",
      " 2   WEEKDAY    58492 non-null  int64  \n",
      " 3   AIRLINE    58492 non-null  object \n",
      " 4   ORG_AIR    58492 non-null  object \n",
      " 5   DEST_AIR   58492 non-null  object \n",
      " 6   SCHED_DEP  58492 non-null  int64  \n",
      " 7   DEP_DELAY  57659 non-null  float64\n",
      " 8   AIR_TIME   57474 non-null  float64\n",
      " 9   DIST       58492 non-null  int64  \n",
      " 10  SCHED_ARR  58492 non-null  int64  \n",
      " 11  ARR_DELAY  57474 non-null  float64\n",
      " 12  DIVERTED   58492 non-null  int64  \n",
      " 13  CANCELLED  58492 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/flights.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16251632-c6bc-44b8-8a65-cf2df20ed42d",
   "metadata": {},
   "source": [
    "`-` 예제1: 항공사(AIRLINE)별로 도착지연시간의(ARR_DELAY)의 평균을 구하라. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae5f6af-4e99-4d03-94f9-40fd9c10b85e",
   "metadata": {},
   "source": [
    "`-` 예제2: 항공사(AIRLINE)별로 비행취소건수(CANCELLED)의 합계를 구하라. 취소건수가 가장 높은 두개의 항공사는 어디인가? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff928dd-9cf2-4ffb-9c32-d3daf7ae53a7",
   "metadata": {},
   "source": [
    "`-` 예제3: 항공사(AIRLINE)별로 비행취소율(CANCELLED)을 구하라. 비행취소율이 가장 높은 두개의 항공사는 어디인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6e580a-077f-447c-a803-b7f13375f778",
   "metadata": {},
   "source": [
    "`-` 예제4: 비행취소율이 가장 높은 두개의 항공사(AIRLINE)를 선택하라. 그 두 항공사에 대하여 요일별(WEEKDAY) 비행취소율(CANCELLED)을 조사하라."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008ddb9b-99d9-4ada-9d3b-380cef3c9e89",
   "metadata": {},
   "source": [
    "`-` 예제5: 아래는 운행거리의 요약통계량이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fbee8cc5-6bfc-4155-a000-88c22ab91830",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    58492.000000\n",
       "mean       872.900072\n",
       "std        624.996805\n",
       "min         67.000000\n",
       "25%        391.000000\n",
       "50%        690.000000\n",
       "75%       1199.000000\n",
       "max       4502.000000\n",
       "Name: DIST, dtype: float64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.DIST.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5043b14e-4a86-463e-8c6d-239e0b18a548",
   "metadata": {},
   "source": [
    "운행거리를 구간별로 `[-np.inf,391,690,1199,np.inf]`와 같이 나눈뒤 비행취소건수와 취소율을 구하여라. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0497a1c8-b8fc-4aab-80a1-4babd7cde816",
   "metadata": {},
   "source": [
    "# Quiz: HRDataset_v14 자료분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e6f666-fb37-4172-8846-d967b2617bf8",
   "metadata": {},
   "source": [
    "아래의 코드를 활용하여 Kaggle의 [HRdataset](https://www.kaggle.com/datasets/rhuebner/human-resources-data-set)을 불러오라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c904ab1-95d4-4fae-ac52-464de2f638a5",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee_Name</th>\n",
       "      <th>EmpID</th>\n",
       "      <th>MarriedID</th>\n",
       "      <th>MaritalStatusID</th>\n",
       "      <th>GenderID</th>\n",
       "      <th>EmpStatusID</th>\n",
       "      <th>DeptID</th>\n",
       "      <th>PerfScoreID</th>\n",
       "      <th>FromDiversityJobFairID</th>\n",
       "      <th>Salary</th>\n",
       "      <th>...</th>\n",
       "      <th>ManagerName</th>\n",
       "      <th>ManagerID</th>\n",
       "      <th>RecruitmentSource</th>\n",
       "      <th>PerformanceScore</th>\n",
       "      <th>EngagementSurvey</th>\n",
       "      <th>EmpSatisfaction</th>\n",
       "      <th>SpecialProjectsCount</th>\n",
       "      <th>LastPerformanceReview_Date</th>\n",
       "      <th>DaysLateLast30</th>\n",
       "      <th>Absences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adinolfi, Wilson  K</td>\n",
       "      <td>10026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>62506</td>\n",
       "      <td>...</td>\n",
       "      <td>Michael Albert</td>\n",
       "      <td>22.0</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>Exceeds</td>\n",
       "      <td>4.60</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1/17/2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ait Sidi, Karthikeyan</td>\n",
       "      <td>10084</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>104437</td>\n",
       "      <td>...</td>\n",
       "      <td>Simon Roup</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>Fully Meets</td>\n",
       "      <td>4.96</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2/24/2016</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akinkuolie, Sarah</td>\n",
       "      <td>10196</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>64955</td>\n",
       "      <td>...</td>\n",
       "      <td>Kissy Sullivan</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>Fully Meets</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5/15/2012</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alagbe,Trina</td>\n",
       "      <td>10088</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>64991</td>\n",
       "      <td>...</td>\n",
       "      <td>Elijiah Gray</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>Fully Meets</td>\n",
       "      <td>4.84</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1/3/2019</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anderson, Carol</td>\n",
       "      <td>10069</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>50825</td>\n",
       "      <td>...</td>\n",
       "      <td>Webster Butler</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Google Search</td>\n",
       "      <td>Fully Meets</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2/1/2016</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Woodson, Jason</td>\n",
       "      <td>10135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>65893</td>\n",
       "      <td>...</td>\n",
       "      <td>Kissy Sullivan</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>Fully Meets</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2/28/2019</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Ybarra, Catherine</td>\n",
       "      <td>10301</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48513</td>\n",
       "      <td>...</td>\n",
       "      <td>Brannon Miller</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Google Search</td>\n",
       "      <td>PIP</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9/2/2015</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Zamora, Jennifer</td>\n",
       "      <td>10010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>220450</td>\n",
       "      <td>...</td>\n",
       "      <td>Janet King</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Employee Referral</td>\n",
       "      <td>Exceeds</td>\n",
       "      <td>4.60</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2/21/2019</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Zhou, Julia</td>\n",
       "      <td>10043</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>89292</td>\n",
       "      <td>...</td>\n",
       "      <td>Simon Roup</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Employee Referral</td>\n",
       "      <td>Fully Meets</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2/1/2019</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Zima, Colleen</td>\n",
       "      <td>10271</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>45046</td>\n",
       "      <td>...</td>\n",
       "      <td>David Stanley</td>\n",
       "      <td>14.0</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>Fully Meets</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1/30/2019</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Employee_Name  EmpID  MarriedID  MaritalStatusID  GenderID  \\\n",
       "0         Adinolfi, Wilson  K  10026          0                0         1   \n",
       "1    Ait Sidi, Karthikeyan     10084          1                1         1   \n",
       "2           Akinkuolie, Sarah  10196          1                1         0   \n",
       "3                Alagbe,Trina  10088          1                1         0   \n",
       "4            Anderson, Carol   10069          0                2         0   \n",
       "..                        ...    ...        ...              ...       ...   \n",
       "306            Woodson, Jason  10135          0                0         1   \n",
       "307        Ybarra, Catherine   10301          0                0         0   \n",
       "308          Zamora, Jennifer  10010          0                0         0   \n",
       "309               Zhou, Julia  10043          0                0         0   \n",
       "310             Zima, Colleen  10271          0                4         0   \n",
       "\n",
       "     EmpStatusID  DeptID  PerfScoreID  FromDiversityJobFairID  Salary  ...  \\\n",
       "0              1       5            4                       0   62506  ...   \n",
       "1              5       3            3                       0  104437  ...   \n",
       "2              5       5            3                       0   64955  ...   \n",
       "3              1       5            3                       0   64991  ...   \n",
       "4              5       5            3                       0   50825  ...   \n",
       "..           ...     ...          ...                     ...     ...  ...   \n",
       "306            1       5            3                       0   65893  ...   \n",
       "307            5       5            1                       0   48513  ...   \n",
       "308            1       3            4                       0  220450  ...   \n",
       "309            1       3            3                       0   89292  ...   \n",
       "310            1       5            3                       0   45046  ...   \n",
       "\n",
       "        ManagerName  ManagerID  RecruitmentSource PerformanceScore  \\\n",
       "0    Michael Albert       22.0           LinkedIn          Exceeds   \n",
       "1        Simon Roup        4.0             Indeed      Fully Meets   \n",
       "2    Kissy Sullivan       20.0           LinkedIn      Fully Meets   \n",
       "3      Elijiah Gray       16.0             Indeed      Fully Meets   \n",
       "4    Webster Butler       39.0      Google Search      Fully Meets   \n",
       "..              ...        ...                ...              ...   \n",
       "306  Kissy Sullivan       20.0           LinkedIn      Fully Meets   \n",
       "307  Brannon Miller       12.0      Google Search              PIP   \n",
       "308      Janet King        2.0  Employee Referral          Exceeds   \n",
       "309      Simon Roup        4.0  Employee Referral      Fully Meets   \n",
       "310   David Stanley       14.0           LinkedIn      Fully Meets   \n",
       "\n",
       "     EngagementSurvey EmpSatisfaction SpecialProjectsCount  \\\n",
       "0                4.60               5                    0   \n",
       "1                4.96               3                    6   \n",
       "2                3.02               3                    0   \n",
       "3                4.84               5                    0   \n",
       "4                5.00               4                    0   \n",
       "..                ...             ...                  ...   \n",
       "306              4.07               4                    0   \n",
       "307              3.20               2                    0   \n",
       "308              4.60               5                    6   \n",
       "309              5.00               3                    5   \n",
       "310              4.50               5                    0   \n",
       "\n",
       "    LastPerformanceReview_Date DaysLateLast30 Absences  \n",
       "0                    1/17/2019              0        1  \n",
       "1                    2/24/2016              0       17  \n",
       "2                    5/15/2012              0        3  \n",
       "3                     1/3/2019              0       15  \n",
       "4                     2/1/2016              0        2  \n",
       "..                         ...            ...      ...  \n",
       "306                  2/28/2019              0       13  \n",
       "307                   9/2/2015              5        4  \n",
       "308                  2/21/2019              0       16  \n",
       "309                   2/1/2019              0       11  \n",
       "310                  1/30/2019              0        2  \n",
       "\n",
       "[311 rows x 36 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/HRDataset_v14.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a08ba3a-7cb6-43c9-8814-3b750f10545c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f268209c890>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('RaceDesc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323ff414-65bb-4cac-b5c6-bde7e11f6c50",
   "metadata": {},
   "source": [
    "`1`. 데이터를 조사하고 올바르게 분석한 사람을 모두 고르라. (모두 맞칠경우만 정답으로 인정)\n",
    "\n",
    "- 소윤: 근무인원수가 가장 많은 인종(RaceDesc)은 'White'이며 이는 'Asian'인종과 'Black or African American'의 합보다 많다. \n",
    "- 다호: 'RaceDesc==White'의 성별(Sex)임금차이는 2000이상이다. \n",
    "- 하니: 퇴직한사람(Termd==1)은 모두 104명이며 백인여성의 퇴직자수가 가장 많다. \n",
    "- 도한: 퇴직한사람중 아시아인의 비율은 10%가 넘지 않는다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
